2019-Jun-09 17:03:40 log.py[line:146]/INFO/  Scrapy 1.6.0 started (bot: urlScrapy)
2019-Jun-09 17:03:40 log.py[line:149]/INFO/  Versions: lxml 4.3.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.0, Python 3.7.3 | packaged by conda-forge | (default, Mar 27 2019, 23:18:50) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.6.1, Platform Windows-10-10.0.17134-SP0
2019-Jun-09 17:03:40 crawler.py[line:38]/INFO/  Overridden settings: {'BOT_NAME': 'urlScrapy', 'CONCURRENT_REQUESTS': 10, 'CONCURRENT_REQUESTS_PER_DOMAIN': 16, 'CONCURRENT_REQUESTS_PER_IP': 16, 'DOWNLOAD_DELAY': 3, 'NEWSPIDER_MODULE': 'urlScrapy.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['urlScrapy.spiders']}
2019-Jun-09 17:03:40 telnet.py[line:60]/INFO/  Telnet Password: 34f1edd474e97be3
2019-Jun-09 17:03:40 middleware.py[line:48]/INFO/  Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-Jun-09 17:03:41 middleware.py[line:48]/INFO/  Enabled downloader middlewares:
['proxyPool.scrapy.middlewares.RetryMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'proxyPool.scrapy.middlewares.ProxyMiddleware',
 'proxyPool.scrapy.middlewares.CatchExceptionMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'proxyPool.scrapy.RandomUserAgentMiddleware.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-Jun-09 17:03:41 middleware.py[line:48]/INFO/  Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-Jun-09 17:03:41 middleware.py[line:48]/INFO/  Enabled item pipelines:
['urlScrapy.pipelines.UrlscrapyPipeline']
2019-Jun-09 17:03:41 engine.py[line:256]/INFO/  Spider opened
2019-Jun-09 17:03:41 logstats.py[line:48]/INFO/  Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-Jun-09 17:03:41 telnet.py[line:74]/INFO/  Telnet console listening on 127.0.0.1:6023
2019-Jun-09 17:03:41 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:41 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:41 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:42 redirect.py[line:41]/DEBUG/  Redirecting (302) to <GET http://www.alexa.cn/plugin/tips?k=WVLC8GHS2OhE7NmlQ5BTg6hKfEap9jd2KSASAB7Gp2u-A-ABvcTmEvO7PDj18q4V5Xjlnc5GtVdk9f0F9FyjNX-IN6gRXcVpqoCyUyFXtagLYXNJrhTykOwbXziWAwC8-AyTa2nm2Ys1BAGYLBYhA3-IAb-Ajdu5hynq66TJSpRjK9SzKQ7Lpa4MnpwqJDNgT7r7Pnw3htfT92l31NRo85Wztqpg-O-O> from <GET http://www.alexa.cn/robots.txt>
2019-Jun-09 17:03:42 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1362, in returnValue
    raise _DefGen_Return(val)
twisted.internet.defer._DefGen_Return: <302 http://www.alexa.cn/robots.txt>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:42 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1362, in returnValue
    raise _DefGen_Return(val)
twisted.internet.defer._DefGen_Return: <302 http://www.alexa.cn/robots.txt>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:42 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/plugin/tips?k=WVLC8GHS2OhE7NmlQ5BTg6hKfEap9jd2KSASAB7Gp2u-A-ABvcTmEvO7PDj18q4V5Xjlnc5GtVdk9f0F9FyjNX-IN6gRXcVpqoCyUyFXtagLYXNJrhTykOwbXziWAwC8-AyTa2nm2Ys1BAGYLBYhA3-IAb-Ajdu5hynq66TJSpRjK9SzKQ7Lpa4MnpwqJDNgT7r7Pnw3htfT92l31NRo85Wztqpg-O-O> (referer: http://www.alexa.cn/robots.txt)
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1362, in returnValue
    raise _DefGen_Return(val)
twisted.internet.defer._DefGen_Return: <200 http://www.alexa.cn/plugin/tips?k=WVLC8GHS2OhE7NmlQ5BTg6hKfEap9jd2KSASAB7Gp2u-A-ABvcTmEvO7PDj18q4V5Xjlnc5GtVdk9f0F9FyjNX-IN6gRXcVpqoCyUyFXtagLYXNJrhTykOwbXziWAwC8-AyTa2nm2Ys1BAGYLBYhA3-IAb-Ajdu5hynq66TJSpRjK9SzKQ7Lpa4MnpwqJDNgT7r7Pnw3htfT92l31NRo85Wztqpg-O-O>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1362, in returnValue
    raise _DefGen_Return(val)
twisted.internet.defer._DefGen_Return: <200 http://www.alexa.cn/plugin/tips?k=WVLC8GHS2OhE7NmlQ5BTg6hKfEap9jd2KSASAB7Gp2u-A-ABvcTmEvO7PDj18q4V5Xjlnc5GtVdk9f0F9FyjNX-IN6gRXcVpqoCyUyFXtagLYXNJrhTykOwbXziWAwC8-AyTa2nm2Ys1BAGYLBYhA3-IAb-Ajdu5hynq66TJSpRjK9SzKQ7Lpa4MnpwqJDNgT7r7Pnw3htfT92l31NRo85Wztqpg-O-O>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/siterank/> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:46 scraper.py[line:158]/ERROR/  Spider error processing <GET http://www.alexa.cn/siterank/> (referer: http://www.alexa.cn/siterank/)
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\models.py", line 375, in prepare_url
    scheme, auth, host, port, path, query, fragment = parse_url(url)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\urllib3\util\url.py", line 199, in parse_url
    raise LocationParseError(url)
urllib3.exceptions.LocationParseError: Failed to parse: http: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\urlScrapy\urlScrapy\spiders\url_dns.py", line 39, in parse
    mytext = requests.get(page)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\sessions.py", line 498, in request
    prep = self.prepare_request(req)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\sessions.py", line 441, in prepare_request
    hooks=merge_hooks(request.hooks, self.hooks),
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\models.py", line 309, in prepare
    self.prepare_url(url, params)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\models.py", line 377, in prepare_url
    raise InvalidURL(*e.args)
requests.exceptions.InvalidURL: Failed to parse: http: 
2019-Jun-09 17:03:50 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Bilibili.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:03:50 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:50 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:50 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:50 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:50 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=3a7b063aAHPUUQyntIq-HTLaBzOOKNsZ82agMK8o-HXIfVYsUMF44OWRY62LE-Aw1o-O&url=Bilibili.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:03:50 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:50 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=c4a27f0apLL4plccfWuOQv6X0b4Cu3JJmRhBmxj5sY9kd6fldzFnMzeLhXwFoXo-N&url=Bilibili.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:03:50 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:50 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=303f0f7cihMqjEjnmf0hONmD9WlxBdHxLOBPNu-ClgMG2Nj9XfKh22PgXqPltBXs-L&url=Bilibili.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:03:50 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:51 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=d3635780O1U37MCaTgV2PPt-I2se7RDFVBFPBtOpt6XAIQoO8e1YEK1ujPstQ-A7Q-M&url=Bilibili.com HTTP/1.1" 200 None
2019-Jun-09 17:03:51 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Bilibili.com>
{'com_name': '上海宽娱数码科技有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '18',
 'create_day': '2004-10-21',
 'domain': 'bilibili.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '沪ICP备13002172号-3',
 'icp_type': '企业',
 'nserver': 'NS3.DNSV5.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comBilibili.com',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Bilibili.com',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '106.75.240.94',
 'server_location': '北京市',
 'server_type': 'Tengine',
 'web_home': 'www.bilibili.com',
 'web_name': '哔哩哔哩弹幕网',
 'world_rank': '46',
 'world_uv_rank': '57'}
2019-Jun-09 17:03:54 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Gmw.cn> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:03:54 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:54 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:54 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:54 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:54 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=73419f0dDN-FQAGKtGLO6tbwW968xHqKAGs9N3dY9R4SITmTBOVOSnHOHEZWQQlk-K&url=Gmw.cn&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:03:54 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:55 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=ddfba702KoDOO9BMRRsKhvNXsnvhVX0LEjD4KOUJVRfOPJAt7yoDjcZjmozCj08-N&url=Gmw.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:03:55 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:55 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=facc9d2ezOrglMB0YePzVCx1ma4pNnHH3C0zPpMGDY0aut9SQ0xPMszqL0kTpfc-K&url=Gmw.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:03:55 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:55 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=8ce75929TLL6D3pwHadIkipq4WkcyC3FGHZv0S34UiHkIPoDyNPKbOyeg0xdcBA-K&url=Gmw.cn HTTP/1.1" 200 None
2019-Jun-09 17:03:55 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Gmw.cn>
{'com_name': '光明网传媒有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '17',
 'create_day': '2003-03-17',
 'domain': 'gmw.cn',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP备09109312号-1',
 'icp_type': '企业',
 'nserver': 'cns1.zdnscloud.net',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comGmw.cn',
 'reg_server': '北京新网数码信息技术有限公司',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Gmw.cn',
 'server': 'WHOIS.CNNIC.CN',
 'server_ip': '183.131.168.145',
 'server_location': '浙江省湖州市',
 'server_type': 'nginx',
 'web_home': 'www.gmw.cn',
 'web_name': '光明网',
 'world_rank': '57',
 'world_uv_rank': '42'}
2019-Jun-09 17:03:58 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Alipay.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:03:58 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:58 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:03:58 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:03:58 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:58 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=41dd94ac7m8A5K8gqb2wQwp3yE3ycC5GLQTiXkZ881sygop6y6wvyxCTJpLMikw-M&url=Alipay.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:03:58 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:58 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=d3a4a1a5p7bmnckyd-GYFIB5i2ckZvscTgaoFQLuoHzxYwOo9Psn1MUrKF2fD-G8Q-M&url=Alipay.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:03:58 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:58 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=fbcf55b4i5oIJLEcYLc3mpzR-BOmlRMlR8Ki5-Gr7FQG1A0MdJK4Hq6otU5eP1asM-L&url=Alipay.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:03:58 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:03:59 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=fe84e3258RqnsJk1mUJaYffMqEA9D-JVcbzr2-CgDGKceUadiTV92wxHOsMx92Rns-L&url=Alipay.com HTTP/1.1" 200 None
2019-Jun-09 17:03:59 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Alipay.com>
{'com_name': '支付宝（中国）网络技术有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '15',
 'create_day': '2004-10-08',
 'domain': 'alipay.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '沪ICP备15027489号-2',
 'icp_type': '企业',
 'nserver': 'NS1.ALIPAY.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comAlipay.com',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Alipay.com',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '110.75.231.7',
 'server_location': '浙江省杭州市',
 'server_type': 'Tengine/2.1.0',
 'web_home': 'www.alipay.com',
 'web_name': '新支付宝',
 'world_rank': '34',
 'world_uv_rank': '36'}
2019-Jun-09 17:04:01 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Csdn.net> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:01 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:01 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:01 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:04:01 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:01 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=9dfc3063XGQUrwA9PLXpuiccaRdmliMGB9ebC-Fqwd6-FDIAUOhPwr8eIs0GTsql0-N&url=Csdn.net&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:01 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:01 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=37f4f304gmBAmiWq1nM38uBZsKTQE98YmzQxWaDX2RfRx027GVw6HB8G3iWh7Po-N&url=Csdn.net&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:01 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:01 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=1be5926ffwy-CZH1agMN-Hs7OJDrQU1psJsmy8XUtR2LUh7pPKC7G4qIeQ0UETSGA-L&url=Csdn.net&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:01 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:01 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=26dbe4bfZI-E-JdU0RikewxYgDn6EgQ-E8-JKwQVgeiOvUg1UFeeq-JeHzOrfxmDcjfc-M&url=Csdn.net HTTP/1.1" 200 None
2019-Jun-09 17:04:01 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Csdn.net>
{'com_name': '北京创新乐知信息技术有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '13',
 'create_day': '1999-03-11',
 'domain': 'csdn.net',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备09002463号-6',
 'icp_type': '企业',
 'nserver': 'VIP3.ALIDNS.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comCsdn.net',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Csdn.net',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '47.95.164.112',
 'server_location': '北京市',
 'server_type': 'openresty',
 'web_home': 'www.csdn.net',
 'web_name': 'CSDN软件开发网',
 'world_rank': '28',
 'world_uv_rank': '35'}
2019-Jun-09 17:04:04 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/360.cn> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:04 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:04 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:04 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:04:04 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:04 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=db64f9ec4aENrHTZdeZAKR3ZUtz07ghOyvzhGpDPwwWlT3wzC0pfTJqIZz2Rur4-L&url=360.cn&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:04 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:04 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=9ae210bcr8NyBJ1q28Ywdt-G7vemMEQZoVE-Gq4511OIqjx2A6vStr40hayW8W9I4-N&url=360.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:04 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:05 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=04ba25fdxSXkuNQj9YSWbGtnEsFsJs5mok1rpxaic8NQj0u2NWUsMQBU8SxY-F8M-M&url=360.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:05 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:05 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=8515c5ba0mtWGGRqInI5RImy0XYGCglG8XdHBeKAW9IHwsmCGQlXOWlgfCXWgvw-M&url=360.cn HTTP/1.1" 200 None
2019-Jun-09 17:04:05 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/360.cn>
{'com_name': '北京奇虎科技有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '11',
 'create_day': '2003-03-17',
 'domain': '360.cn',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备08010314号-6',
 'icp_type': '企业',
 'nserver': 'dns9.360safe.com',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.com360.cn',
 'reg_server': '厦门易名科技股份有限公司',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=360.cn',
 'server': 'WHOIS.CNNIC.CN',
 'server_ip': '36.110.213.49',
 'server_location': '北京市',
 'server_type': 'nginx',
 'web_home': 'www.360.cn<br/>www.360safe.com',
 'web_name': '360安全中心',
 'world_rank': '22',
 'world_uv_rank': '23'}
2019-Jun-09 17:04:08 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Weibo.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:08 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:08 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:08 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:04:08 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:08 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=d0cd7954VTxXB5KJIFB8qfEJgDBVAX2S1JCbR4nsxRfTeme9stmSgNXocHSwu-E0-O&url=Weibo.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:08 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:08 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=1aaafe852zCVni-JZWw-BWTKIBgrVWefixV4UmTSAENdWSQE-BozoPlZgRe-Bt2yiHk-O&url=Weibo.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:08 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:08 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=00a054a4QfgD0CJcoyitB3mLWdt3-IKuIP6d1f8UBlgkEIs6RzsEElfh3N5LC9f4-O&url=Weibo.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:08 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:08 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=ca14a5fdeOhuHEs87Gosq1pHK1iIXSLcQwxuOctRBdlmnq3mHUQGPG0SFfIHbcM-N&url=Weibo.com HTTP/1.1" 200 None
2019-Jun-09 17:04:08 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Weibo.com>
{'com_name': '北京微梦创科网络技术有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '8',
 'create_day': '1999-03-20',
 'domain': 'weibo.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备12002058号-2',
 'icp_type': '企业',
 'nserver': 'NS1.SINA.COM.CN',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comWeibo.com',
 'reg_server': 'XIAMEN 35.COM TECHNOLOGY CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Weibo.com',
 'server': 'WHOIS.35.COM',
 'server_ip': '180.149.134.142',
 'server_location': '北京市',
 'server_type': 'WeiBo',
 'web_home': 'www.weibo.com',
 'web_name': '微博平台',
 'world_rank': '17',
 'world_uv_rank': '18'}
2019-Jun-09 17:04:12 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Sina.com.cn> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:12 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:12 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:12 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:04:12 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:12 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=7feb85ecH-BewZjIjZquhwzKDeio8EWpn4vS7L5eoITotG5McapbEi8cVLmcJDl0-O&url=Sina.com.cn&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:12 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:13 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=0a567715wmwLRBdJpsn8Vs71A2CUEQssFABE8EtD3HNv3rkCZSP-GLugrGm4tcng-K&url=Sina.com.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:13 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:13 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=a308caf7O6HrCa0lnGCJm5I-CSjxKLjStRZ-COvrumkcwWcoJoRKdUoKJfxR-CbeRc-N&url=Sina.com.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:13 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:13 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=08a978adFaqrWliyTRivejhg0wvpybS9fPKWnengZ-GoHhyi5GBq89UQCy0zR56E-N&url=Sina.com.cn HTTP/1.1" 200 None
2019-Jun-09 17:04:13 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Sina.com.cn>
{'com_name': '北京新浪互联信息服务有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '7',
 'create_day': '1998-11-20',
 'domain': 'sina.com.cn',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '京ICP证000007-6',
 'icp_type': '企业',
 'nserver': 'ns3.sina.com.cn',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comSina.com.cn',
 'reg_server': '北京新网数码信息技术有限公司',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Sina.com.cn',
 'server': 'WHOIS.CNNIC.CN',
 'server_ip': '115.238.190.239',
 'server_location': '浙江省宁波市',
 'server_type': 'nginx',
 'web_home': 'www.sina.com.cn',
 'web_name': '新浪网',
 'world_rank': '16',
 'world_uv_rank': '16'}
2019-Jun-09 17:04:15 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Jd.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:15 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:15 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:15 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:04:15 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:15 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=1b223caeJDWV8tPdvWLsnnZRhtmytJhotEpHJ9vzhXJZTJP7xW5Dxwv73Ye0xig-L&url=Jd.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:15 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:15 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=0050d043Qc4hynyzjCk2j0NP-I3TlFTcoamP9zpiOAdLkwbi38M8Rjer27NcXRCQ-O&url=Jd.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:15 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:15 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=288c7633VwTy1lgdpL4O9kILNsc9cGSTTMLRqdoc-Bm2EdX4gVL3WjDCLmEXOXiU-M&url=Jd.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:15 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:16 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=04e3ea59YTl7WltNW2TjAHhA9MOqNFjY-IzdmledEHRINtQUE-BBptD4M2D-IeoxHM-L&url=Jd.com HTTP/1.1" 200 None
2019-Jun-09 17:04:16 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Jd.com>
{'com_name': '北京京东叁佰陆拾度电子商务有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '6',
 'create_day': '1992-09-29',
 'domain': 'jd.com',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '京ICP备11041704号-3',
 'icp_type': '企业',
 'nserver': 'NS1.JDCACHE.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comJd.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Jd.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '61.174.55.1',
 'server_location': '浙江省金华市',
 'server_type': 'JDWS/2.0',
 'web_home': 'www.360buy.com',
 'web_name': '京东商城;京东多媒体网',
 'world_rank': '13',
 'world_uv_rank': '17'}
2019-Jun-09 17:04:19 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Sohu.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:19 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:19 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:19 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:04:19 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:19 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=11042a2a-DeafjHu8Ccl21XzStFZ0TZI8AKRttr4mtW40y7Y69xVhsGMeMHLv-DKs-M&url=Sohu.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:19 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:19 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=532457dckSZOV-BYlmUCzyInsQI7RdFMTJEGKZc6H1kXGYZjo7E3SW-BVbTHZBsT0-K&url=Sohu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:19 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:20 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=8a646c91ANcY84EVF2SmqZdKSNidmBT-ALjSQeZ5N32lBPFzKmIrniRLRtJ8Z1CE-M&url=Sohu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:20 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:20 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=619ae07f1J0Nae47kl3Jtc-A4ndlLvPQfxVfCmFCNynFWhguGutBYalO6w0DrsE8-L&url=Sohu.com HTTP/1.1" 200 None
2019-Jun-09 17:04:20 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Sohu.com>
{'com_name': '北京搜狐互联网信息服务有限公司',
 'content_type': 'Content-Type: text/html;charset=UTF-8',
 'country_code': 'CN',
 'country_rank': '5',
 'create_day': '1998-07-05',
 'domain': 'sohu.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP证030367号-1',
 'icp_type': '企业',
 'nserver': 'NS11.SOHU.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comSohu.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Sohu.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '211.159.191.17',
 'server_location': '北京市',
 'server_type': 'nginx',
 'web_home': 'www.sohu.com',
 'web_name': '搜狐网',
 'world_rank': '12',
 'world_uv_rank': '12'}
2019-Jun-09 17:04:23 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Tmall.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:23 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:23 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 17:04:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 None 】 =====
2019-Jun-09 17:04:23 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:23 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=89c56105jG1yYf4WpBy8Dehlibcn3AKuSA1ZBICyHeXp0HdbSCLocEmnWmsfbgg-M&url=Tmall.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:23 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:24 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=2d5c816c-ClQMEXFxHOFnJLaMx6TeHM4VIATcP2jT0ntKNHC-GHEIU5HDEnbW8-C3c-N&url=Tmall.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:24 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:24 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=49b996c8GurJ87LofsmFFSfBqMQpmvSV1cf4DUIHflPvkfdpCgd93uFm7lRbc2Q-K&url=Tmall.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:24 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:24 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=ca91d7edBvE-CjH47dVWjFnjpfSj-C-CsyXqyWAHL2lA-CzF60EoaLQlw-CcDAF0GqVA-L&url=Tmall.com HTTP/1.1" 200 None
2019-Jun-09 17:04:24 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Tmall.com>
{'com_name': '浙江天猫网络有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '4',
 'create_day': '1997-10-17',
 'domain': 'tmall.com',
 'http_type': 'HTTP/1.1 302 Found',
 'icp_no': '浙B2-20110446-1',
 'icp_type': '企业',
 'nserver': 'NS4.TAOBAO.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comTmall.com',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Tmall.com',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '101.37.183.170',
 'server_location': '浙江省杭州市',
 'server_type': 'Tengine',
 'web_home': 'www.tmall.com',
 'web_name': '天猫',
 'world_rank': '8',
 'world_uv_rank': '7'}
2019-Jun-09 17:04:27 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Babytree.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:27 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:27 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=0bd39a5c5wm0wWEvizxPoaBXlu8ycRZncw95nV-EObxR3wbiuJ6hQVRBB8lSFwdA-M&url=Babytree.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:27 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:28 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=2734716erksVbzOyV-CKF2ODxTCmZne05L450t4QJiJEr6fnpOCcdqw6yiDfzMO8-L&url=Babytree.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:28 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:28 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=8813f3cb-Dp-DXOtuT676dS0-FTnjlNGK-Fv-DDWDlvwL4pVYnoJRCzCPsJjvm-FwknQs-O&url=Babytree.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:28 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:28 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=107299b4B-CIu1gmGRIuTxVYR7SQFfhPNeOkVlEBjmIsORW0cryxVqkjP-Fur2vGg-O&url=Babytree.com HTTP/1.1" 200 None
2019-Jun-09 17:04:28 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Babytree.com>
{'com_name': '北京众鸣世纪科技有限公司',
 'content_type': 'Content-Type: text/html; charset=utf-8',
 'country_code': 'CN',
 'country_rank': '26',
 'create_day': '2004-09-06',
 'domain': 'babytree.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP备11010348号-1',
 'icp_type': '企业',
 'nserver': 'NS1.DNSV5.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comBabytree.com',
 'reg_server': 'ENOM, INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Babytree.com',
 'server': 'WHOIS.ENOM.COM',
 'server_ip': '59.110.149.245',
 'server_location': '北京市',
 'server_type': 'nginx',
 'web_home': 'www.babytree.com',
 'web_name': '众鸣世纪',
 'world_rank': '83',
 'world_uv_rank': '91'}
2019-Jun-09 17:04:31 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Zhihu.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:32 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:32 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=768523e5Q5WgMaOt4z-I2k2sfiZWT0X5BguuBkXe80qDRcG5RkMz6fE7cnaGoIlo-L&url=Zhihu.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:32 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:32 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=b1775560f5LRpzkd3VnkOKi-Ht683f-BUyYpCKDxdZTktbsyui6w2WCBqhP736IkE-N&url=Zhihu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:32 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:32 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=204eb9b5XJ0ekQdQ1o6-EiXVNW0Di0e3jUp5Ak2N3LDttCZEkkV5tW4apPnXw3-HQ-N&url=Zhihu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:32 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:32 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=2a25b24e-BPWRG9hoVUHQ1fCWhIX3NBkaemDYBRsvCMhS9-Br0mgSGY-BzAtYr345I-M&url=Zhihu.com HTTP/1.1" 200 None
2019-Jun-09 17:04:32 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Zhihu.com>
{'com_name': '北京智者天下科技有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '25',
 'create_day': '2007-06-16',
 'domain': 'zhihu.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备13052560号-1',
 'icp_type': '企业',
 'nserver': 'NS3.DNSV5.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comZhihu.com',
 'reg_server': 'GODADDY.COM, LLC',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Zhihu.com',
 'server': 'WHOIS.GODADDY.COM',
 'server_ip': '118.89.204.190',
 'server_location': '天津市滨海新区',
 'server_type': 'ZWS',
 'web_home': 'www.zhihu.com',
 'web_name': '知乎',
 'world_rank': '82',
 'world_uv_rank': '81'}
2019-Jun-09 17:04:34 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Cnblogs.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:34 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:34 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=7a361206G-FdrJJkGeUj5-FKN-FZJWB3cu1aPT1mQunn9ATyvZTvOZHHjr-E-EFNTo-F0-K&url=Cnblogs.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:34 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:35 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=344bfbdfjA-JTGqDz8NxPT0khed8xSpnILAakvw8G5WHPllS1aoPNnTfr-JBuDdhE-N&url=Cnblogs.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:35 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:35 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=06694400mU-JLD-JRQELyT0iQ27RQIz-JLcA31VWxbyTzXqFn-Aa-JjeW-J-Jbb2QuH90w-N&url=Cnblogs.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:35 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:35 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=cc07294d51WsC9ILFLa90msqfQqsRYEHBnEue4Fxh1qrfqMtKjfk6SEojwp3Rvw-O&url=Cnblogs.com HTTP/1.1" 200 None
2019-Jun-09 17:04:35 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Cnblogs.com>
{'com_name': '上海语程信息科技有限公司',
 'content_type': 'Content-Type: text/html; charset=utf-8',
 'country_code': 'CN',
 'country_rank': '24',
 'create_day': '2003-11-11',
 'domain': 'cnblogs.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '沪ICP备09004260号-1',
 'icp_type': '企业',
 'nserver': 'NS3.DNSV4.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comCnblogs.com',
 'reg_server': '35 TECHNOLOGY CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Cnblogs.com',
 'server': 'WHOIS.35.COM',
 'server_ip': '47.96.240.190',
 'server_location': '浙江省杭州市',
 'server_type': '',
 'web_home': 'www.cnweblog.com',
 'web_name': '博客园',
 'world_rank': '78',
 'world_uv_rank': '75'}
2019-Jun-09 17:04:38 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Hao123.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:38 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:38 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=f7786d5frfeBcDpZHte7GtgPGV-BrLqxBryIOrMUoEFKln3G5j3qOkiCU05my5m4-N&url=Hao123.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:38 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:38 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=d4eb2356Gx6Pa88q3-AS1DvnKWjtKFE4b2tGGru3SlKEdWH-Hg6GamjMlVUZzoXas-M&url=Hao123.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:38 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:39 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=8b4fb2f8C-H0knQHePhRfKaze98dSvIU6R3GelD6TNjFjqcQE6z6MrJQMJZw0TAI-L&url=Hao123.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:39 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:39 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=d79922bbr3ZjYvP0jDBwMacJQ-Im2ypH596ai2-EglYQ0NjTxTJ23zhiVYMSY6RzA-L&url=Hao123.com HTTP/1.1" 200 None
2019-Jun-09 17:04:39 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Hao123.com>
{'com_name': '北京百度网讯科技有限公司',
 'content_type': 'Content-Type: text/html;charset=UTF-8',
 'country_code': 'CN',
 'country_rank': '22',
 'create_day': '2000-11-15',
 'domain': 'hao123.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP证030173号-25',
 'icp_type': '企业',
 'nserver': 'DNS.BAIDU.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comHao123.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Hao123.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '115.239.217.167',
 'server_location': '浙江省杭州市',
 'server_type': 'Apache',
 'web_home': 'www.hao123.com',
 'web_name': '网址之家',
 'world_rank': '65',
 'world_uv_rank': '58'}
2019-Jun-09 17:04:41 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Soso.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:41 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:41 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=a6de8027pDbQTClGhrDMRx1LemS9JSIEtOWZLQu9LVnMcLb8CWV0eV5SoyIpvoI-K&url=Soso.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:41 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:41 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=3cc4e7947-IEvw4RDHl-AJ0Lj95XsLgWJmUITPrjlPZePNmyW5eaeN75cJOyEvE7U-M&url=Soso.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:41 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:41 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=cc414fd1ojj90eYRtGuENxjqel8mo3Zd6HdkJlZ-CurTnkzviDytKQ1mFuPwrr68-K&url=Soso.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:41 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:41 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=d04498f25Kq0cyT2OMjHpVZcfqWjdxfQICpfqsq9yNSIfxI33aEQ8OMNcEX7nFg-M&url=Soso.com HTTP/1.1" 200 None
2019-Jun-09 17:04:41 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Soso.com>
{'com_name': '北京搜狗信息服务有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '20',
 'create_day': '0000-00-00',
 'domain': 'soso.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP备11001839号-4',
 'icp_type': '企业',
 'nserver': 'ns1.sogou.com',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comSoso.com',
 'reg_server': '',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Soso.com',
 'server': 'WHOIS.VERISIGN-GRS.COM',
 'server_ip': '183.36.114.44',
 'server_location': '广东省广州市',
 'server_type': 'nginx',
 'web_home': 'www.soso.com',
 'web_name': 'soso网',
 'world_rank': '68',
 'world_uv_rank': '67'}
2019-Jun-09 17:04:41 logstats.py[line:48]/INFO/  Crawled 17 pages (at 17 pages/min), scraped 15 items (at 15 items/min)
2019-Jun-09 17:04:45 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Xinhuanet.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=85dd33a7YDaCR166pPPkf9EmROH3wd-HEo8cCXs0uHcB0fhVihMAhl-Hj0bc7onBc-L&url=Xinhuanet.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=8c009530NscGaWGEJII80q2VPRkGGUbmCa-AHu06xmzqP5mPl3LGHW9WgJeNNSeA-O&url=Xinhuanet.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=192b272f8WG7x-JwDcWATjtLdp2W6ctZ8oCSmH5Eztrh1qHlXE95l5DeLbdRAqDw-L&url=Xinhuanet.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=c1d71af7mj0J1itqF-A5nOj-Am2lclTyrq3uro9x1TT3pgF9mqDgwBbX0yK7UX1jc-O&url=Xinhuanet.com HTTP/1.1" 200 None
2019-Jun-09 17:04:45 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Xinhuanet.com>
{'com_name': '新华网股份有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '21',
 'create_day': '2000-04-28',
 'domain': 'xinhuanet.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP证010042号-2',
 'icp_type': '企业',
 'nserver': 'NS1.CDNS.CN',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comXinhuanet.com',
 'reg_server': 'BEIJING SANFRONT INFORMATION TECHNOLOGY CO., LTD',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Xinhuanet.com',
 'server': 'WHOIS.SFN.CN',
 'server_ip': '183.131.127.122',
 'server_location': '浙江省台州市',
 'server_type': 'nginx',
 'web_home': 'www.xinhuanet.com',
 'web_name': '新华网',
 'world_rank': '67',
 'world_uv_rank': '77'}
2019-Jun-09 17:04:49 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/163.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:49 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:49 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=f99e1b1dgGuNNFmnVvPaVcbjhxeWw1nvl67-IkWFSUX4GPLmMiNNYoLsmqEyZtuc-N&url=163.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:49 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:50 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=820361cfpW3hNbaqBAiFBdYXSnQcAkF0rxA7bwHwdOTWUTYiOMvqGW3Phlf7j6U-L&url=163.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:50 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:50 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=d6d214c0laxEUqH4PcgVYT0-IEt3JqJF-I3r2jdMnIPXpMBWhnQUnxJTZrcwIdQdc-M&url=163.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:50 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:50 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=2b2d17feiraIdJE-Fkt49kchu6vonMi4ws8BbHD4GVdouggRKBK-E-FK7fXjwQyl-Fw-N&url=163.com HTTP/1.1" 200 None
2019-Jun-09 17:04:50 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/163.com>
{'com_name': '广州网易计算机系统有限公司',
 'content_type': '',
 'country_code': 'CN',
 'country_rank': '19',
 'create_day': '1997-09-15',
 'domain': '163.com',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '粤B2-20090191-18',
 'icp_type': '企业',
 'nserver': 'NS1.NEASE.NET',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.com163.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=163.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '122.226.47.94',
 'server_location': '浙江省金华市',
 'server_type': 'Cdn Cache Server V2.0',
 'web_home': 'www.163.com',
 'web_name': '网易',
 'world_rank': '70',
 'world_uv_rank': '69'}
2019-Jun-09 17:04:52 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Taobao.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:52 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:52 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=ed5c24a3r-AZ-Gtjs6DxYclaUkI6IQVLypeqSoouJVdzVVqHymt87lXIm47Ox0DAM-K&url=Taobao.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:52 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:52 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=31eb9694-BxGP0ns9jKAWMNX5cf32brvYT3VH4JzxVPjMxdvdGZiWLyBvLCFP7zs-L&url=Taobao.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:52 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:52 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=5fffa28fqyk6K4mT4n8c-AU5j-Au3fC0uG6L3V8SF-A3Yo5jMo1NPpkxIVJ62Lc6kg-L&url=Taobao.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:52 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:52 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=7bad2b68RHKZPkV9okyTuKXiG-BCb9QdB3Dv-B5r-BntznS1kezTv90DaaL8HgDyyY-L&url=Taobao.com HTTP/1.1" 200 None
2019-Jun-09 17:04:53 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Taobao.com>
{'com_name': '浙江淘宝网络有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '3',
 'create_day': '2003-04-21',
 'domain': 'taobao.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '浙B2-20080224-1',
 'icp_type': '企业',
 'nserver': 'NS4.TAOBAO.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comTaobao.com',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Taobao.com',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '101.37.183.171',
 'server_location': '浙江省杭州市',
 'server_type': 'Tengine',
 'web_home': 'www.taobao.com',
 'web_name': '淘宝',
 'world_rank': '7',
 'world_uv_rank': '8'}
2019-Jun-09 17:04:56 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Qq.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:04:56 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:56 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=498920b2pR-EgAWvEmcmeaYS3Lv-EzpGgQdiheFUx1tvMG4IGNE68qFqjRm8AS-EAE-N&url=Qq.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:04:56 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:56 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=cecc74afpKpRE5MzfYgmERMrnGe5al9KtQEWJayhcnhBPY-GzWPYBDWR1ptJ7SgA-L&url=Qq.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:56 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:56 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=55012957Y-EKIiIfWJpRpmo5P-EQ8aPiCuVzAbL-HqFeTDo-HOcF6vo0NFrr2CM6OJU-K&url=Qq.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:04:56 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:04:56 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=1a9e20b33dJqHgP5cnN66BgAOOfr5wHiGPrfjUsO1PktsksQxJ2FjtObbmZgo3o-N&url=Qq.com HTTP/1.1" 200 None
2019-Jun-09 17:04:56 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Qq.com>
{'com_name': '深圳市腾讯计算机系统有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '2',
 'create_day': '1995-05-04',
 'domain': 'qq.com',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '粤B2-20090059-5',
 'icp_type': '企业',
 'nserver': 'NS1.QQ.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comQq.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Qq.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '58.250.137.36',
 'server_location': '广东省深圳市',
 'server_type': 'stgw/1.3.10.6_1.13.5',
 'web_home': 'www.qq.com',
 'web_name': '腾讯网',
 'world_rank': '6',
 'world_uv_rank': '6'}
2019-Jun-09 17:05:00 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Baidu.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 17:05:00 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:05:00 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=16f87c9fVh-GFFhWc4Demkoup2M7DLEZrJV03-GFQEaDXtCFLcWMKYDJ27hePo95Q-N&url=Baidu.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 17:05:00 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:05:00 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=1e021a12eo1IEkiFoT7oBzOspk3f-F5Eyq2LpgbJrO70hWHz0bhRAtSoYDINQx08-K&url=Baidu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:05:00 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:05:00 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=7495fc439h7DpA1iW1AzlkAU8p1HRvedAz-GVRpX3MEj1erCOItBBBeZjFo5ykQk-O&url=Baidu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 17:05:00 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 17:05:00 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=5811c10boxsgBUChwc1kH8B24-IRJc4fIkWY2-EWgKL5Ul0-EPS8ljbVi04zx41h-Ec-O&url=Baidu.com HTTP/1.1" 200 None
2019-Jun-09 17:05:00 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Baidu.com>
{'com_name': '北京百度网讯科技有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '1',
 'create_day': '1999-10-11',
 'domain': 'baidu.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP证030173号-1',
 'icp_type': '企业',
 'nserver': 'NS1.BAIDU.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comBaidu.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Baidu.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '115.239.210.27',
 'server_location': '浙江省杭州市',
 'server_type': 'bfe/1.0.8.18',
 'web_home': 'www.baidu.com',
 'web_name': '百度',
 'world_rank': '4',
 'world_uv_rank': '4'}
2019-Jun-09 17:05:00 engine.py[line:295]/INFO/  Closing spider (finished)
2019-Jun-09 17:05:00 statscollectors.py[line:47]/INFO/  Dumping Scrapy stats:
{'downloader/request_bytes': 8694,
 'downloader/request_count': 23,
 'downloader/request_method_count/GET': 23,
 'downloader/response_bytes': 93365,
 'downloader/response_count': 23,
 'downloader/response_status_count/200': 22,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 9, 9, 5, 0, 928850),
 'item_scraped_count': 20,
 'log_count/DEBUG': 226,
 'log_count/ERROR': 47,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 22,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'spider_exceptions/InvalidURL': 1,
 'start_time': datetime.datetime(2019, 6, 9, 9, 3, 41, 916921)}
2019-Jun-09 17:05:00 engine.py[line:326]/INFO/  Spider closed (finished)
